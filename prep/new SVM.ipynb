{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filename = \"enron_random_clean1_senders.pkl\"\n",
    "master = pd.read_pickle(source_filename)\n",
    "master[\"label\"] = master.entity.apply(lambda x: 1 if x == \"signature\" else 0)\n",
    "master = master[master.nSigBlocks > 0]\n",
    "master[\"filename_cat\"] = master.filename.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_columns = [\n",
    "    \"line\", \n",
    "    \"filename\", \n",
    "    \"entity\", \n",
    "    \"label\", \n",
    "    \"nSig\", \n",
    "    \"firstchar\", \n",
    "    'nlines',\n",
    "     'len_avg',\n",
    "    'len_min',\n",
    "    'len_max',\n",
    "    'nBlanks',\n",
    "    'nNonBlanks',\n",
    "    'nSigBlocks',\n",
    "    'pred_label',\n",
    "    \"next_label\",\n",
    "    \"sigToLinesRatio\",\n",
    "    \"pred_file\",\n",
    "    \"next_file\",\n",
    "    \"lineNo\",\n",
    "#   \"len\",\n",
    "    \"pred_named_entity\",\n",
    "    \"named_entity\",\n",
    "    \"next_named_entity\",\n",
    "    \"sender\", \n",
    "    \"sender_name\",\n",
    "    \"filename_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    filenames = df.filename.unique()\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_filenames, test_filenames = train_test_split(filenames, test_size=0.2, random_state=42)\n",
    "    train = df[df.filename.isin(train_filenames)]\n",
    "    test = df[df.filename.isin(test_filenames)]\n",
    "    featured_columns = [c for c in df.columns if c not in excluded_columns]\n",
    "    X_train = train.loc[:, featured_columns]\n",
    "    X_test = test.loc[:, featured_columns]\n",
    "    y_train = train.label\n",
    "    y_test = test.label\n",
    "    return X_train, X_test, y_train, y_test, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_shift_columns = [\"prev_same_entity\", \"next_same_entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_df(df):\n",
    "    prev_val = -1\n",
    "    next_val = 2\n",
    "    df[\"pred_file\"] = df.filename.shift(1, fill_value=prev_val)\n",
    "    df[\"next_file\"] = df.filename.shift(-1, fill_value=next_val)\n",
    "    columns_to_shift = [c for c in df.columns if c not in excluded_columns and c not in no_shift_columns]\n",
    "        \n",
    "    print(f\"Columns to shift: {columns_to_shift}\")\n",
    "    for col in columns_to_shift:\n",
    "        print(f\"Shifting columng {col}\")\n",
    "        pred_name = f\"prev_{col}\"\n",
    "        df[pred_name] = df[col].shift(1, fill_value=prev_val)\n",
    "        df[pred_name] = df.apply(lambda row: row[pred_name] if row.pred_file == row.filename else prev_val, axis=1)\n",
    "        \n",
    "        next_name = f\"next_{col}\"\n",
    "        df[next_name] = df[col].shift(-1, fill_value=next_val)\n",
    "        df[next_name] = df.apply(lambda row: row[next_name] if row.next_file == row.filename else next_val, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'C': [0.002, 0.07, 0.1, 0.5, 1, 1.25, 1.5, 2, 10, 12, 16, 32, 64, 0.047, 0.052, 0.057, 0.062, 0.067, 0.1, 0.5, 1, 1.25, 1.5, 2],\n",
    "#     'C': [0.002, 0.07, 0.1, 0.5, 1, 1.25, 1.5, 2, 10, 12],\n",
    "#     'C': [0.002, 0.07, 0.1, 0.5, 1, 1.25, 1.5, 2],\n",
    "    'class_weight': [\"balanced\", {1: 1}, {1: 2}, {1: 2.5}, {1: 2.25}, {1: 3}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to shift: ['len', 'blank', 'email', 'url', 'phone', 'sigdelimiter', 'special', 'words', 'header', 'name', 'endquote', 'tabs1', 'tabs2', 'tabs3', 'punct20', 'punct50', 'punct90', 'reply', 'startpunct', 'replypunct', 'wrote', 'alphanum90', 'alphanum50', 'alphanum10', 'num90', 'num50', 'num10', 'title', 'many_titles', 'person', 'org', 'posFromEnd', 'last', 'prevlast', 'last5', 'last11', 'posRatio', 'posRatioFromEnd', 'posRatioNB', 'lenRatio', 'lenRatioMax', 'less_avg_len', 'more_avg_len', 'less_avg_len75', 'less_avg_len50', 'has_sender', 'has_sender_name']\n",
      "Shifting columng len\n",
      "Shifting columng blank\n",
      "Shifting columng email\n",
      "Shifting columng url\n",
      "Shifting columng phone\n",
      "Shifting columng sigdelimiter\n",
      "Shifting columng special\n",
      "Shifting columng words\n",
      "Shifting columng header\n",
      "Shifting columng name\n",
      "Shifting columng endquote\n",
      "Shifting columng tabs1\n",
      "Shifting columng tabs2\n",
      "Shifting columng tabs3\n",
      "Shifting columng punct20\n",
      "Shifting columng punct50\n",
      "Shifting columng punct90\n",
      "Shifting columng reply\n",
      "Shifting columng startpunct\n",
      "Shifting columng replypunct\n",
      "Shifting columng wrote\n",
      "Shifting columng alphanum90\n",
      "Shifting columng alphanum50\n",
      "Shifting columng alphanum10\n",
      "Shifting columng num90\n",
      "Shifting columng num50\n",
      "Shifting columng num10\n",
      "Shifting columng title\n",
      "Shifting columng many_titles\n",
      "Shifting columng person\n",
      "Shifting columng org\n",
      "Shifting columng posFromEnd\n",
      "Shifting columng last\n",
      "Shifting columng prevlast\n",
      "Shifting columng last5\n",
      "Shifting columng last11\n",
      "Shifting columng posRatio\n",
      "Shifting columng posRatioFromEnd\n",
      "Shifting columng posRatioNB\n",
      "Shifting columng lenRatio\n",
      "Shifting columng lenRatioMax\n",
      "Shifting columng less_avg_len\n",
      "Shifting columng more_avg_len\n",
      "Shifting columng less_avg_len75\n",
      "Shifting columng less_avg_len50\n",
      "Shifting columng has_sender\n",
      "Shifting columng has_sender_name\n"
     ]
    }
   ],
   "source": [
    "shifted = shift_df(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, train, test = split_df(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:\n",
      "1    1851\n",
      "0    387 \n",
      "Name: nSigBlocks, dtype: int64\n",
      "1    0.827078\n",
      "0    0.172922\n",
      "Name: nSigBlocks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Before SMOTE\n",
    "print(\"Before SMOTE:\")\n",
    "print(train.nSigBlocks.value_counts())\n",
    "print(train.nSigBlocks.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afer SMOTE:\n",
      "1    1851\n",
      "0    740 \n",
      "Name: nSigBlocks, dtype: int64\n",
      "1    0.714396\n",
      "0    0.285604\n",
      "Name: nSigBlocks, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, train, test = split_df(shifted)\n",
    "# Add temporarily\n",
    "X_train[\"label\"] = train.label\n",
    "X_train[\"nSigBlocks\"] = train.nSigBlocks\n",
    "X_train[\"filename_code\"] = train.filename_cat.cat.codes\n",
    "\n",
    "# Apply smote\n",
    "sm = SMOTE(random_state=42, sampling_strategy=.4)\n",
    "X_train, y_train_nSigBlocks = sm.fit_resample(X_train, train.nSigBlocks)\n",
    "y_train = X_train.label\n",
    "\n",
    "# After SMOTE\n",
    "print(\"Afer SMOTE:\")\n",
    "print(X_train.nSigBlocks.value_counts())\n",
    "print(X_train.nSigBlocks.value_counts(normalize=True))\n",
    "\n",
    "# Cleanup\n",
    "train_filenames = X_train[\"filename_code\"]\n",
    "X_train.drop([\"label\", \"filename_code\", \"nSigBlocks\"], axis=1, inplace=True)\n",
    "\n",
    "assert \"label\" not in X_train.columns\n",
    "assert \"filename_code\" not in X_train.columns\n",
    "assert len(y_train) == len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 17.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1177 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1277 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1381 tasks      | elapsed: 25.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.819\n",
      "\n",
      "Best params: {'C': 0.057, 'class_weight': {1: 1}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 26.0min finished\n"
     ]
    }
   ],
   "source": [
    "svc = svm.LinearSVC(random_state=42, dual=True, max_iter=100000)\n",
    "clf = GridSearchCV(svc, parameters, scoring=\"f1\", cv=GroupKFold(n_splits=10), n_jobs=-1, refit=False, verbose=10)\n",
    "clf.fit(X_train, y_train, groups=train_filenames)\n",
    "\n",
    "print(f\"Best score: {clf.best_score_:.3}\")\n",
    "print()\n",
    "print(f\"Best params: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7910447761194029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Programs\\Anaconda2\\envs\\thesis-enron\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear = svm.LinearSVC(C=16, random_state=42, dual=True, class_weight={1: 2.25}, max_iter=100000)\n",
    "linear.fit(X_train, y_train)\n",
    "linear_pred = linear.predict(X_test)\n",
    "print(f1_score(y_true=y_test, y_pred=linear_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.957     0.972       507\n",
      "           1      0.707     0.898     0.791        59\n",
      "\n",
      "    accuracy                          0.951       566\n",
      "   macro avg      0.847     0.927     0.881       566\n",
      "weighted avg      0.958     0.951     0.953       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=linear_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = linear_pred\n",
    "TP = test[(test.label == 1) & (test.pred == 1)] # is signature and predicted signature\n",
    "TN = test[(test.label == 0) & (test.pred == 0)] # is not signature and predicted not signature\n",
    "\n",
    "FP = test[(test.label == 0) & (test.pred == 1)] # is not signature but predicted signature\n",
    "FN = test[(test.label == 1) & (test.pred == 0)] # is signature but predicted not signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[485  22]\n",
      " [  6  53]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, linear_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['len', 'blank', 'email', 'url', 'phone', 'sigdelimiter', 'special',\n",
       "       'words', 'header', 'name', 'endquote', 'tabs1', 'tabs2', 'tabs3',\n",
       "       'punct20', 'punct50', 'punct90', 'reply', 'startpunct', 'replypunct',\n",
       "       'wrote', 'alphanum90', 'alphanum50', 'alphanum10', 'num90', 'num50',\n",
       "       'num10', 'title', 'many_titles', 'person', 'org', 'posFromEnd', 'last',\n",
       "       'prevlast', 'last5', 'last11', 'posRatio', 'posRatioFromEnd',\n",
       "       'posRatioNB', 'lenRatio', 'lenRatioMax', 'less_avg_len', 'more_avg_len',\n",
       "       'less_avg_len75', 'less_avg_len50', 'prev_same_entity',\n",
       "       'next_same_entity', 'has_sender', 'has_sender_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prediction(row):    \n",
    "    same_file = row.pred_file == row.filename and row.next_file == row.filename\n",
    "    if not same_file:\n",
    "        return row.pred\n",
    "    \n",
    "    if row.pred_predict == 1 and row.next_predict == 1:        \n",
    "        return 1\n",
    "    if row.pred_predict == 0 and row.next_predict == 0:        \n",
    "        return 0\n",
    "        \n",
    "    return row.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.990     0.970     0.980       507\n",
      "           1      0.783     0.915     0.844        59\n",
      "\n",
      "    accuracy                          0.965       566\n",
      "   macro avg      0.886     0.943     0.912       566\n",
      "weighted avg      0.968     0.965     0.966       566\n",
      "\n",
      "\n",
      "Before blocking:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.957     0.972       507\n",
      "           1      0.707     0.898     0.791        59\n",
      "\n",
      "    accuracy                          0.951       566\n",
      "   macro avg      0.847     0.927     0.881       566\n",
      "weighted avg      0.958     0.951     0.953       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test[\"pred\"] = linear_pred\n",
    "test[\"pred_predict\"] = test.pred.shift(1)\n",
    "test[\"next_predict\"] = test.pred.shift(-1)\n",
    "test[\"pred_file\"] = test.filename.shift(1)\n",
    "test[\"next_file\"] = test.filename.shift(-1)\n",
    "test[\"new_pred\"] = test.apply(lambda row: update_prediction(row), axis=1)\n",
    "print(classification_report(y_true=test.label, y_pred=test.new_pred, digits=3))\n",
    "print(\"\\nBefore blocking:\")\n",
    "print(classification_report(y_true=test.label, y_pred=test.pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.557\n"
     ]
    }
   ],
   "source": [
    "print(f\"{precision_score(y_true=test.label, y_pred=test.pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with blocking: 0.573\n",
      "Recall with blocking: 0.729\n",
      "F1 with blocking: 0.642\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision with blocking: {precision_score(y_true=test.label, y_pred=test.new_pred):.3f}\")\n",
    "print(f\"Recall with blocking: {recall_score(y_true=test.label, y_pred=test.new_pred):.3f}\")\n",
    "print(f\"F1 with blocking: {f1_score(y_true=test.label, y_pred=test.new_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     0.953     0.969       579\n",
      "           1      0.585     0.826     0.685        46\n",
      "\n",
      "    accuracy                          0.944       625\n",
      "   macro avg      0.785     0.890     0.827       625\n",
      "weighted avg      0.956     0.944     0.948       625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=test.loc[test.blank==0].label, y_pred=test.loc[test.blank==0].pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[492  15]\n",
      " [  5  54]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test.label, test.new_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[485  22]\n",
      " [  6  53]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test.label, test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.666666666666664"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((15-18)/18)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
